<!DOCTYPE html><html class="hide-aside" lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>统计学习方法--第19章 MCMC | LiuJT's Blog</title><meta name="author" content="LiuJT"><meta name="copyright" content="LiuJT"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="特别说明：书中马氏链定义 $p_{ij}$ 是 $t-1$ 时刻从 $j$ 出发，$t$ 时刻到达 $i$ ，因此与随机过程教材的写法不一致，具体体现在状态转移矩阵是转置的，因此这里的随机矩阵定义的是列和为 1 。两者说法本质是一样的，只是记号相反，按照随机过程定义请看以下 pdf。   1. 蒙特卡洛 蒙特卡罗法也称为 统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。 马尔可夫链">
<meta property="og:type" content="article">
<meta property="og:title" content="统计学习方法--第19章 MCMC">
<meta property="og:url" content="http://example.com/2024/10/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC19%E7%AB%A0%20MCMC%E6%96%B9%E6%B3%95/index.html">
<meta property="og:site_name" content="LiuJT&#39;s Blog">
<meta property="og:description" content="特别说明：书中马氏链定义 $p_{ij}$ 是 $t-1$ 时刻从 $j$ 出发，$t$ 时刻到达 $i$ ，因此与随机过程教材的写法不一致，具体体现在状态转移矩阵是转置的，因此这里的随机矩阵定义的是列和为 1 。两者说法本质是一样的，只是记号相反，按照随机过程定义请看以下 pdf。   1. 蒙特卡洛 蒙特卡罗法也称为 统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。 马尔可夫链">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/08/28/K8FcuStCQYsTV4A.jpg">
<meta property="article:published_time" content="2024-10-11T16:00:00.000Z">
<meta property="article:modified_time" content="2024-11-03T08:32:13.183Z">
<meta property="article:author" content="LiuJT">
<meta property="article:tag" content="统计学习方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/08/28/K8FcuStCQYsTV4A.jpg"><link rel="shortcut icon" href="https://s2.loli.net/2024/08/28/WOMi84ksFx3dGY1.jpg"><link rel="canonical" href="http://example.com/2024/10/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC19%E7%AB%A0%20MCMC%E6%96%B9%E6%B3%95/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '统计学习方法--第19章 MCMC',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-11-03 16:32:13'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/WOMi84ksFx3dGY1.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-calendar"></i><span> 时间</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-cogs"></i><span> 分类</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-archive"></i><span> 统计学习方法</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-archive"></i><span> 概率理论</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 常用软件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Pycharm/"><i class="fa-fw fas fa-cogs"></i><span> Pycharm</span></a></li><li><a class="site-page child" href="/LaTeX/"><i class="fa-fw fas fa-cogs"></i><span> LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('https://s2.loli.net/2024/08/28/K8FcuStCQYsTV4A.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="LiuJT's Blog"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-calendar"></i><span> 时间</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-cogs"></i><span> 分类</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-archive"></i><span> 统计学习方法</span></a></div><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-archive"></i><span> 概率理论</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 常用软件</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Pycharm/"><i class="fa-fw fas fa-cogs"></i><span> Pycharm</span></a></li><li><a class="site-page child" href="/LaTeX/"><i class="fa-fw fas fa-cogs"></i><span> LaTeX</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">统计学习方法--第19章 MCMC</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-10-11T16:00:00.000Z" title="发表于 2024-10-12 00:00:00">2024-10-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="统计学习方法--第19章 MCMC"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>特别说明：书中马氏链定义 $p_{ij}$ 是 $t-1$ 时刻从 $j$ 出发，$t$ 时刻到达 $i$ ，因此与随机过程教材的写法不一致，具体体现在状态转移矩阵是转置的，因此这里的随机矩阵定义的是列和为 1 。两者说法本质是一样的，只是记号相反，按照随机过程定义请看以下 pdf。</p>
<embed src="PDF/MCMC.pdf" type="application/pdf" width="100%" height="600px">

<h3 id="1-蒙特卡洛"><a href="#1-蒙特卡洛" class="headerlink" title="1. 蒙特卡洛"></a>1. 蒙特卡洛</h3><ul>
<li><strong>蒙特卡罗法</strong>也称为 统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。</li>
<li><strong>马尔可夫链蒙特卡罗法</strong>（Markov Chain Monte Carlo, MCMC），则是以马尔可夫链（Markov chain）为概率模型的蒙特卡罗法。</li>
</ul>
<p>MCMC 构建一个马氏链，使平稳分布就是要进行抽样的分布，首先基于该马尔可夫链进行随机游走，产生样本的序列，之后使用该平稳分布的样本进行近似数值计算。经典算法有：</p>
<ul>
<li>Metropolis-Hastings 算法是最基本的马尔可夫链蒙特卡罗法，Metropolis 等人在 1953 年提出原始的算法，Hastings 在 1970 年对之加以推广，形成了现在的形式。</li>
<li>吉布斯抽样（Gibbs sampling）是更简单、使用更广泛的马尔可夫链蒙特卡罗法，1984年由 S. Geman 和 D. Geman 提出。</li>
</ul>
<p>马尔可夫链蒙特卡罗法被应用于概率分布的估计、定积分的近似计算、最优化问题的近似求解等问题，特别是被应用于统计学习中概率模型的学习与推理，是重要的统计学习计算方法。</p>
<h4 id="1-1-随机抽样"><a href="#1-1-随机抽样" class="headerlink" title="1.1 随机抽样"></a>1.1 随机抽样</h4><ul>
<li>统计学和机器学习的目的：基于数据对概率分布的特征进行推断，从样本得到经验分布, 从而估计总体分布。</li>
<li>蒙特卡罗法要解决的问题是, 假设概率分布的定义已知, 通过抽样获得概率分布的随机样本, 并通过得到的随机样本对概率分布的特征进行分析。如从样本计算出样本均值，从而估计总体期望。蒙特卡罗法的核心是<strong>随机抽样 (random sampling)</strong>。</li>
</ul>
<blockquote>
<p>Remark：<strong>统计学</strong>通过收集和分析数据来推断总体的特征，<strong>机器学习</strong>则更进一步，它通过训练模型来学习数据的潜在模式和结构。通常假设数据是从某个未知的概率分布中生成的，并通过训练过程来逼近这个分布。<strong>蒙特卡罗法</strong>是一种基于随机抽样的方法，用于在已知概率分布的情况下，通过生成随机样本并分析这些样本来估计分布的特征。</p>
<p>既然已知概率分布，为什么还要随机抽样获取样本？直接计算复杂性：对于某些复杂、高维的概率分布，直接计算其特征（如期望值、方差等）非常困难或不可行。例如，某些积分的求解可能需要高维度的计算，这在解析上是非常复杂的。通过随机抽样，可以避免这些复杂的计算，转而通过样本的平均值来估计这些特征。</p>
</blockquote>
<p>一般的蒙特卡罗法有<strong>直接抽样法、接受-拒绝抽样法、重要性抽样法</strong>等。接受-拒绝抽样法、重要性抽样法适合于<strong>概率密度函数复杂</strong>（如密度函数含有多个变量，各变量相互不独立，密度函数形式复杂），不能直接抽样的情况。</p>
<h5 id="1-1-1-直接抽样"><a href="#1-1-1-直接抽样" class="headerlink" title="1.1.1 直接抽样"></a>1.1.1 直接抽样</h5><p>直接采样的思想是：计算机适合于随机的均匀采样，如果能够把任意概率分布的采样转化成对均匀分布的采样，就可以解决采样问题。均匀分布转换为其他分布：</p>
<ul>
<li>逆变换（Box-Muller 变换）</li>
<li>舍选法</li>
</ul>
<h5 id="1-1-2-接受拒绝抽样"><a href="#1-1-2-接受拒绝抽样" class="headerlink" title="1.1.2 接受拒绝抽样"></a>1.1.2 接受拒绝抽样</h5><p>假设有随机变量 $x$, 取值 $x \in \mathcal{X}$ 。目标是得到该概率分布的随机样本, 以对这个概率分布进行分析。</p>
<p>接受-拒绝法的基本想法如下：</p>
<ul>
<li>假设其概率密度函数为 $p(x)$ 不可以直接抽样。</li>
<li>找一个可以直接抽样的分布，称为建议分布（proposal distribution）。假设其概率密度函数为 $q(x)$，并且有 $q(x)$ 的 $c$ 倍一定大于等于 $p(x)$, 其中 $c&gt;0$ 。</li>
<li>按照 $q(x)$ 进行抽样，假设得到结果是 $x^<em>$ ，再按照 $\frac{p\left(x^</em>\right)}{c q\left(x^{<em>}\right)}$ 的比例随机决定是否接受 $x^</em>$。</li>
</ul>
<p>直观上，落到 $p\left(x^<em>\right)$ 范围内的就接受，落到 $p\left(x^{</em>}\right)$ 范围外的就拒绝（红色）。接受-拒绝法实际是按照 $p(x)$ 的涵盖面积（或涵盖体积）占 $cq(x)$ 的涵盖面积（或涵盖体积）的比例进行抽样。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.mathpix.com/cropped/2024_10_12_dad0b5c615992b14ccb2g-367.jpg?height=335&amp;width=561&amp;top_left_y=1191&amp;top_left_x=534" alt="接受-拒绝抽样法"></p>
<p>接受-拒绝法的具体算法如下。</p>
<p>输入：抽样的目标概率分布的概率密度函数 $p(x)$ ；<br>输出: 概率分布的随机样本 $x<em>{1}, x</em>{2}, \cdots, x_{n}$ 。<br>参数：样本数 $n$</p>
<p>（1）选择概率密度函数为 $q(x)$ 的概率分布，作为建议分布，使其对任一 $x$ 满足 $c q(x) \geqslant p(x)$ ，其中 $c&gt;0$ 。</p>
<p>（2）按照建议分布 $q(x)$ 随机抽样得到样本 $x^{*}$ ，再按照均匀分布在 $(0,1)$ 范围内抽样得到 $u$ 。</p>
<p>（3） 如果 $u \leqslant \frac{p\left(x^{<em>}\right)}{c q\left(x^{</em>}\right)}$, 则将 $x^{*}$ 作为抽样结果; 否则, 回到步骤 (2)。</p>
<p>（4）直至得到 $n$ 个随机样本，结束。</p>
<ul>
<li>优点是容易实现，</li>
<li>缺点是效率可能不高。</li>
</ul>
<blockquote>
<p>如果 $p(x)$ 的涵盖体积占 $c q(x)$ 的涵盖体积的比例很低，就会<strong>导致拒绝的比例很高，抽样效率很低</strong>。注意，一般是在<strong>高维空间</strong>进行抽样，即使 $p(x)$ 与 $c q(x)$ 很接近，两者涵盖体积的差异也可能很大。</p>
</blockquote>
<p>$\color{red}{Remark：常数与建议分布的选择很重要}$</p>
<h5 id="1-1-3-重要性抽样"><a href="#1-1-3-重要性抽样" class="headerlink" title="1.1.3 重要性抽样"></a>1.1.3 重要性抽样</h5><h4 id="1-2-蒙特卡洛应用"><a href="#1-2-蒙特卡洛应用" class="headerlink" title="1.2 蒙特卡洛应用"></a>1.2 蒙特卡洛应用</h4><h4 id="1-2-1-数学期望估计"><a href="#1-2-1-数学期望估计" class="headerlink" title="1.2.1 数学期望估计"></a>1.2.1 数学期望估计</h4><p>一般的蒙特卡罗法也可以用于<strong>数学期望估计</strong>。假设有随机变量 $x$ ，取值 $x \in \mathcal{X}$ ，其概率密度函数为 $p(x), f(x)$ 为定义在 $\mathcal{X}$ 上的函数，目标是求函数 $f(x)$ 关于密度函数 $p(x)$ 的数学期望 $E_{p(x)}[f(x)]$ 。</p>
<p>蒙特卡罗法按照概率分布 $p(x)$ 用以上的抽样方法，独立地抽取 $n$ 个样本 $x<em>{1}, x</em>{2}, \cdots, x_{n}$ ，之后计算函数 $f(x)$ 的样本均值 $\hat{f}_n$</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{f}_{n}=\frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right)
\end{equation*}</script><p>作为数学期望 $E_{p(x)}[f(x)]$ 的近似值。</p>
<p>理论保证（大数定律）：当样本容量增大时, 样本均值以概率 1 收敛到数学期望:</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{f}_{n} \rightarrow E_{p(x)}[f(x)], \quad n \rightarrow \infty
\end{equation*}</script><p>于是得到数学期望的近似计算方法:</p>
<script type="math/tex; mode=display">
\begin{equation*}
E_{p(x)}[f(x)] \approx \frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right)
\end{equation*}</script><h4 id="1-2-2-积分计算"><a href="#1-2-2-积分计算" class="headerlink" title="1.2.2 积分计算"></a>1.2.2 积分计算</h4><p>一般的蒙特卡罗法也可以用于<strong>定积分的近似计算</strong>，称为<strong>蒙特卡罗积分</strong>。假设有一个函数 $h(x)$, 目标是计算该函数的积分</p>
<script type="math/tex; mode=display">
\int_{\mathcal{X}} h(x) \mathrm{d} x</script><p>如果能够将函数 $h(x)$ 分解成一个函数 $f(x)$ 和一个概率密度函数 $p(x)$ 的乘积的形式，那么就有</p>
<script type="math/tex; mode=display">
\begin{equation*}
\int_{\mathcal{X}} h(x) \mathrm{d} x=\int_{\mathcal{X}} f(x) p(x) \mathrm{d} x=E_{p(x)}[f(x)]
\end{equation*}</script><p>于是函数 $h(x)$ 的积分可以表示为函数 $f(x)$ 关于概率密度函数 $p(x)$ 的数学期望。实际上，给定一个概率密度函数 $p(x)$ ，只要取 $f(x)=\frac{h(x)}{p(x)}$ ，就可得上式</p>
<script type="math/tex; mode=display">
\begin{equation*}
\int_{\mathcal{X}} h(x) \mathrm{d} x=\int_{\mathcal{X}} \frac{h(x)}{p(x)}p(x) \mathrm{d} x=E_{p(x)}[\frac{h(x)}{p(x)}]
\end{equation*}</script><p>我们可以看到</p>
<ul>
<li>任何一个函数的积分都可以表示为某一个函数的数学期望的形式</li>
<li>而函数的数学期望又可以通过函数的样本均值估计</li>
</ul>
<p>于是就可以利用样本均值来近似计算积分。这就是蒙特卡罗积分的基本想法。</p>
<script type="math/tex; mode=display">
\begin{equation*}
\int_{\mathcal{X}} h(x) \mathrm{d} x=E_{p(x)}[\frac{h(x)}{p(x)}] \approx \frac{1}{n} \sum_{i=1}^{n} \frac{h(x_i)}{p(x_i)}
\end{equation*}</script><p><strong>例 1</strong> 用蒙特卡罗积分法求 $\int_{0}^{1} e^{-x^{2} / 2} \mathrm{~d} x$<br>解 令 $f(x)=\mathrm{e}^{-x^{2} / 2}$</p>
<script type="math/tex; mode=display">
p(x)=1 \quad(0<x<1)</script><p>也就是说，假设随机变量 $x$ 在 $(0,1)$ 区间遵循均匀分布。<br>使用蒙特卡罗积分法，如图所示，在 $(0,1)$ 区间按照均匀分布抽取 10 个随机样本 $x<em>{1}, x</em>{2}, \cdots, x<em>{10}$ 。计算样本的函数均值 $\hat{f}</em>{10}$</p>
<script type="math/tex; mode=display">
\hat{f}_{10}=\frac{1}{10} \sum_{i=1}^{10} \mathrm{e}^{-x_{i}^{2} / 2}=0.832</script><p>也就是积分的近似。随机样本数越大，计算就越精确。</p>
<p><strong>例 2</strong> 用蒙特卡罗积分法求 $\int_{-\infty}^{\infty} x \frac{1}{\sqrt{2 \pi}} \exp \left(\frac{-x^{2}}{2}\right) \mathrm{d} x$ 。<br>解 令 $f(x)=x$</p>
<script type="math/tex; mode=display">
p(x)=\frac{1}{\sqrt{2 \pi}} \exp \left(\frac{-x^{2}}{2}\right)</script><p>$p(x)$ 是标准正态分布的密度函数，于是</p>
<script type="math/tex; mode=display">
\begin{equation*}
\int_{\mathcal{X}} h(x) \mathrm{d} x=\int_{\mathcal{X}} f(x) p(x) \mathrm{d} x=E_{p(x)}[x]
\end{equation*}</script><p>$\color{red}{虽然我们知道可以解析推导正态分布的期望}$，但还是使用蒙特卡罗积分法，按照标准正态分布在区间 $(-\infty, \infty)$ 抽样 $x<em>{1}, x</em>{2}, \cdots, x<em>{n}$ ，取其平均值 $\bar{x}=\frac{1}{n} \sum</em>{i=1}^{n} \mathrm{x_i}$, 就得到要求的积分值。由大数定理我们知道，当样本增大时, 积分值（样本均值）趋于数学期望 。</p>
<p>本章介绍的马尔科夫链蒙特卡罗法也适合于<strong>概率密度函数复杂，不能直接抽样</strong>的情况，旨在解决一般的蒙特卡罗法，如<strong>接受-拒绝抽样法、重要性抽样法，抽样效率不高</strong>的问题。</p>
<p>注意：一般的蒙特卡罗法中的抽样样本是<strong>独立</strong>的，而马尔可夫链蒙特卡罗法中的抽样样本<strong>不是独立</strong>的，样本序列形成马尔科夫链。</p>
<h3 id="2-马氏链"><a href="#2-马氏链" class="headerlink" title="2. 马氏链"></a>2. 马氏链</h3><p>本节首先给出马尔可夫链的定义，之后介绍马尔可夫链的一些性质。</p>
<h4 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h4><p>定义 1 (随机过程) 考虑一个随机变量的序列 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，这里 $X</em>{t}$ 表示时刻 $t$ 的随机变量， $t=0,1,2, \cdots$ 。每个随机变量 $X_{t}(t=0,1,2, \cdots)$ 的取值集合相同，称为状态空间，表示为 $\mathcal{S}$ 。随机变量可以是离散的，也可以是连续的。以上随机变量的序列构成随机过程（stochastic process）。</p>
<p>定义 2（马氏链）假设在时刻 0 的随机变量 $X<em>{0}$ 遵循概率分布 $P\left(X</em>{0}\right)=\pi<em>{0}$ ，称为初始状态分布。在某个时刻 $t \geqslant 1$ 的随机变量 $X</em>{t}$ 与前一个时刻的随机变量 $X<em>{t-1}$ 之间有条件分布 $P\left(X</em>{t} \mid X<em>{t-1}\right)$ ，如果 $X</em>{t}$ 只依赖于 $X<em>{t-1}$ ，而不依赖于过去的随机变量 $\left{X</em>{0}, X<em>{1}, \cdots, X</em>{t-2}\right}$, 这一性质称为马尔可夫性, 即</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t} \mid X_{0}, X_{1}, \cdots, X_{t-1}\right)=P\left(X_{t} \mid X_{t-1}\right), \quad t=1,2, \cdots
\end{equation*}</script><p>具有马尔可夫性的随机序列 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ 称为马尔可夫链（Markov chain），或马尔可夫过程（Markov process）。条件概率分布 $P\left(X</em>{t} \mid X_{t-1}\right)$ 称为马尔可夫链的转移概率分布。转移概率分布决定了马尔可夫链的特性。马尔可夫性的直观解释是 “未来只依赖于现在（假设现在已知），而与过去无关”。</p>
<p>若转移概率分布 $P\left(X<em>{t} \mid X</em>{t-1}\right)$ 与 $t$ 无关, 即</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t+s} \mid X_{t-1+s}\right)=P\left(X_{t} \mid X_{t-1}\right), \quad t=1,2, \cdots ; \quad s=1,2, \cdots
\end{equation*}</script><p>则称该马尔可夫链为时间齐次的马尔可夫链（time homogenous Markov chain）。</p>
<p>以上定义的是一阶马尔可夫链，可以扩展到 $n$ 阶马尔可夫链，满足 $n$ 阶马尔可夫性</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t} \mid X_{0} X_{1} \cdots X_{t-2} X_{t-1}\right)=P\left(X_{t} \mid X_{t-n} \cdots X_{t-2} X_{t-1}\right) \tag{19.8}
\end{equation*}</script><p>容易验证 $n$ 阶马尔可夫链可以转换为一阶马尔可夫链。</p>
<blockquote>
<p>本书主要考虑齐次马氏链和一阶马氏链。</p>
</blockquote>
<h4 id="2-2-离散状态马氏链"><a href="#2-2-离散状态马氏链" class="headerlink" title="2.2 离散状态马氏链"></a>2.2 离散状态马氏链</h4><h5 id="2-2-1-转移概率矩阵和状态分布"><a href="#2-2-1-转移概率矩阵和状态分布" class="headerlink" title="2.2.1 转移概率矩阵和状态分布"></a>2.2.1 转移概率矩阵和状态分布</h5><p>离散状态马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，随机变量 $X</em>{t}(t=0,1,2, \cdots)$定义在离散空间 $\mathcal{S}$ ，转移概率分布可以由矩阵表示。</p>
<p>若马尔可夫链在时刻 $(t-1)$ 处于状态 $j$, 在时刻 $t$ 移动到状态 $i$, 将转移概率记作</p>
<script type="math/tex; mode=display">
\begin{equation*}
p_{i j}=\left(X_{t}=i \mid X_{t-1}=j\right), \quad i=1,2, \cdots ; \quad j=1,2, \cdots
\end{equation*}</script><p>满足</p>
<script type="math/tex; mode=display">
p_{i j} \geqslant 0, \quad \sum_{i} p_{i j}=1</script><p>马尔可夫链的转移概率 $p_{i j}$ 可以由矩阵表示, 即</p>
<script type="math/tex; mode=display">
P=\left[\begin{array}{cccc}
p_{11} & p_{12} & p_{13} & \cdots \\
p_{21} & p_{22} & p_{23} & \cdots \\
p_{31} & p_{32} & p_{33} & \cdots \\
\cdots & \cdots & \cdots & \cdots
\end{array}\right]</script><p>称为马尔可夫链的转移概率矩阵，转移概率矩阵 $P$ 满足条件 $p<em>{i j} \geqslant 0, \sum</em>{i} p_{i j}=1$ 。满足这两个条件的矩阵称为随机矩阵（stochastic matrix）。注意这里矩阵列元素之和为 1 。</p>
<p>考虑马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X_{t}, \cdots\right}$ 在时刻 $t(t=0,1,2, \cdots)$ 的概率分布, 称为时刻 $t$ 的状态分布, 记作</p>
<script type="math/tex; mode=display">
\pi(t)=\left[\begin{array}{c}
\pi_{1}(t) \\
\pi_{2}(t) \\
\vdots
\end{array}\right]</script><p>其中 $\pi<em>{i}(t)$ 表示时刻 $t$ 状态为 $i$ 的概率 $P\left(X</em>{t}=i\right)$，特别地, 马尔可夫链的初始状态分布可以表示为</p>
<script type="math/tex; mode=display">
\pi(0)=\left[\begin{array}{c}
\pi_{1}(0) \\
\pi_{2}(0) \\
\vdots
\end{array}\right]</script><p>其中 $\pi<em>{i}(0)$ 表示时刻 0 状态为 $i$ 的概率 $P\left(X</em>{0}=i\right)$ 。通常初始 分布 $\pi(0)$ 的向量只有一个分量是 1 ，其余分量都是 0 ，表示马尔可夫链从一个具体状态开始。</p>
<p>有限离散状态的马尔可夫链可以由有向图表示。结点表示状态，边表示状态之间的转移，边上的数值表示转移概率。从一个初始状态出发，根据有向边上定义的概率在状态之间随机跳转（或随机转移），就可以产生状态的序列。马尔可夫链实际上是刻画随时间在状态之间转移的模型，假设未来的转移状态只依赖于现在的状态，而与过去的状态无关。</p>
<p>马尔可夫链 $X$ 在时刻 $t$ 的状态分布, 可以由在时刻 $(t-1)$ 的状态分布以及转移概率分布决定</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi(t)=P \pi(t-1)
\end{equation*}</script><p>这是因为</p>
<script type="math/tex; mode=display">
\begin{aligned}
\pi_{i}(t) & =P\left(X_{t}=i\right) \\
& =\sum_{m} P\left(X_{t}=i \mid X_{t-1}=m\right) P\left(X_{t-1}=m\right) \\
& =\sum_{m} p_{i m} \pi_{m}(t-1)
\end{aligned}</script><p>马尔可夫链在时刻 $t$ 的状态分布, 可以通过递推得到。事实上</p>
<script type="math/tex; mode=display">
\pi(t)=P \pi(t-1)=P(P \pi(t-2))=P^{2} \pi(t-2)</script><p>递推得到</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi(t)=P^{t} \pi(0)
\end{equation*}</script><p>这里的 $P^{t}$ 称为 $t$ 步转移概率矩阵,</p>
<script type="math/tex; mode=display">
P_{i j}^{t}=P\left(X_{t}=i \mid X_{0}=j\right)</script><p>表示时刻 0 从状态 $j$ 出发, 时刻 $t$ 达到状态 $i$ 的 $t$ 步转移概率。 $P^{t}$ 也是随机矩阵。这说明，马尔可夫链的状态分布由初始分布和转移概率分布决定。</p>
<h5 id="2-2-2-平稳分布"><a href="#2-2-2-平稳分布" class="headerlink" title="2.2.2 平稳分布"></a>2.2.2 平稳分布</h5><p><strong>定义 2 (平稳分布)</strong>： 设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，其状态空间为 $\mathcal{S}$, 转移概率矩阵为 $P=\left(p</em>{i j}\right)$, 如果存在状态空间 $\mathcal{S}$ 上的一个分布</p>
<script type="math/tex; mode=display">
\pi=\left[\begin{array}{c}
\pi_{1} \\
\pi_{2} \\
\vdots
\end{array}\right]</script><p>使得</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi=P \pi
\end{equation*}</script><p>则称 $\pi$ 为马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X_{t}, \cdots\right}$ 的平稳分布。<br>直观上, 如果马尔可夫链的平稳分布存在, 那么以该平稳分布作为初始分布, 面向未来进行随机状态转移，之后任何一个时刻的状态分布都是该平稳分布。</p>
<p><strong>引理 1</strong> 给定一个马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$, 状态空间为 $\mathcal{S}$, 转移概率矩阵为 $P=\left(p</em>{i j}\right)$, 则分布 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 为 $X$ 的平稳分布的充分必要条件是 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 是下列方程组的解:</p>
<script type="math/tex; mode=display">
\begin{align*}
& x_{i}=\sum_{j} p_{i j} x_{j}, \quad i=1,2, \cdots  \\
& x_{i} \geqslant 0, \quad i=1,2, \cdots  \\
& \sum_{i} x_{i}=1
\end{align*}</script><p>证明 必要性。假设 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 是平稳分布，显然满足式（19.17）和式 (19.18)。又</p>
<script type="math/tex; mode=display">
\pi_{i}=\sum_{j} p_{i j} \pi_{j}, \quad i=1,2, \cdots</script><p>即 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 满足式 $(19.16)$ 。<br>充分性。由式 (19.17) 和式 (19.18) 知 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{T}$ 是一概率分布。假设 $\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 为 $X_{t}$ 的分布, 则</p>
<script type="math/tex; mode=display">
P\left(X_{t}=i\right)=\pi_{i}=\sum_{j} p_{i j} \pi_{j}=\sum_{j} p_{i j} P\left(X_{t-1}=j\right), \quad i=1,2, \cdots</script><p>$\pi=\left(\pi<em>{1}, \pi</em>{2}, \cdots\right)^{\mathrm{T}}$ 也为 $X<em>{t-1}$ 的分布。事实上这对任意 $t$ 成立。所以 $\pi=\left(\pi</em>{1}, \pi_{2}, \cdots\right)^{\mathrm{T}}$ 是马尔可夫链的平稳分布。引理 1 给出一个求马尔可夫链平稳分布的方法。</p>
<h4 id="2-3-连续状态马氏链"><a href="#2-3-连续状态马氏链" class="headerlink" title="2.3 连续状态马氏链"></a>2.3 连续状态马氏链</h4><p>连续状态马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$, 随机变量 $X</em>{t}(t=0,1,2, \cdots)$ 定义在连续状态空间 $\mathcal{S}$ ，转移概率分布由概率转移核或转移核（transition kernel）表示。</p>
<p>设 $\mathcal{S}$ 是连续状态空间，对任意的 $x \in \mathcal{S}, A \subset \mathcal{S}$ ，转移核 $P(x, A)$ 定义为</p>
<script type="math/tex; mode=display">
\begin{equation*}
P(x, A)=\int_{A} p(x, y) \mathrm{d} y
\end{equation*}</script><p>其中 $p(x, \bullet)$ 是概率密度函数, 满足 $p(x, \cdot) \geqslant 0, P(x, \mathcal{S})=\int_{\mathcal{S}} p(x, y) \mathrm{d} y=1$ 。转移核 $P(x, A)$ 表示从 $x \sim A$ 的转移概率</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t}=A \mid X_{t-1}=x\right)=P(x, A)
\end{equation*}</script><p>有时也将概率密度函数 $p(x, \bullet)$ 称为转移核。<br>若马尔可夫链的状态空间 $\mathcal{S}$ 上的概率分布 $\pi(x)$ 满足条件</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi(y)=\int p(x, y) \pi(x) \mathrm{d} x, \quad \forall y \in \mathcal{S}
\end{equation*}</script><p>则称分布 $\pi(x)$ 为该马尔可夫链的平稳分布。等价地,</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi(A)=\int P(x, A) \pi(x) \mathrm{d} x, \quad \forall A \subset \mathcal{S}
\end{equation*}</script><p>或简写为</p>
<script type="math/tex; mode=display">
\begin{equation*}
\pi=P \pi
\end{equation*}</script><h4 id="2-4-马氏链性质"><a href="#2-4-马氏链性质" class="headerlink" title="2.4 马氏链性质"></a>2.4 马氏链性质</h4><h5 id="2-4-1-不可约"><a href="#2-4-1-不可约" class="headerlink" title="2.4.1 不可约"></a>2.4.1 不可约</h5><p>定义3 (不可约) 设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X_{t}, \cdots\right}$, 状态空间为 $\mathcal{S}$, 对于任意状态 $i, j \in \mathcal{S}$, 如果存在一个时刻 $t(t&gt;0)$ 满足</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t}=i \mid X_{0}=j\right)>0
\end{equation*}</script><p>也就是说, 时刻 0 从状态 $j$ 出发, 时刻 $t$ 到达状态 $i$ 的概率大于 0 , 则称此马尔可夫链 $X$ 是不可约的 (irreducible), 否则称马尔可夫链是可约的 (reducible)。</p>
<p>直观上, 一个不可约的马尔可夫链, 从任意状态出发, 当经过充分长时间后, 可以到达任意状态。</p>
<h6 id="2-4-2-非周期"><a href="#2-4-2-非周期" class="headerlink" title="2.4.2 非周期"></a>2.4.2 非周期</h6><p>定义4 (非周期) 设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$, 状态空间为 $\mathcal{S}$ ，对于任意状态 $i \in \mathcal{S}$ ，如果时刻 0 从状态 $i$ 出发， $t$ 时刻返回状态的所有时间长 $\left{t: P\left(X</em>{t}=i \mid X_{0}=i\right)&gt;0\right}$ 的最大公约数是1, 则称此马尔可夫链 $X$ 是非周期的 (aperiodic), 否则称马尔可夫链是周期的 (periodic)。</p>
<p>直观上, 一个非周期性的马尔可夫链, 不存在一个状态, 从这一个状态出发, 再返回到这个状态时所经历的时间长呈一定的周期性。例 19.3 中的马尔可夫链是非周期的，例19.6中的马尔可夫链是周期的。</p>
<p>定理 2 不可约且非周期的有限状态马尔可夫链, 有唯一平稳分布存在。</p>
<h6 id="2-4-3-正常返"><a href="#2-4-3-正常返" class="headerlink" title="2.4.3 正常返"></a>2.4.3 正常返</h6><p>定义5（正常返）设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，状态空间为 $\mathcal{S}$, 对于任意状态 $i, j \in \mathcal{S}$, 定义概率 $p</em>{i j}^{t}$ 为时刻 0 从状态 $j$ 出发, 时刻 $t$ 首次转移到状态 $i$ 的概率, 即 $p<em>{i j}^{t}=P\left(X</em>{t}=i, X<em>{s} \neq i, s=1,2, \cdots, t-1 \mid X</em>{0}=j\right), t=1,2, \cdots$ 。若对所有状态 $i, j$ 都满足 $\lim <em>{t \rightarrow \infty} p</em>{i j}^{t}&gt;0$, 则称马尔可夫链 $X$ 是正常返的 （positive recurrent）。</p>
<p>直观上，一个正常返的马尔可夫链，其中任意一个状态，从其他任意一个状态出发, 当时间趋于无穷时, 首次转移到这个状态的概率不为 0 。例 19.7 中的马尔可夫链根据不同条件是正常返的或不是正常返的。</p>
<p>定理 3 不可约、非周期且正常返的马尔可夫链, 有唯一平稳分布存在。</p>
<h5 id="2-4-4-遍历定理"><a href="#2-4-4-遍历定理" class="headerlink" title="2.4.4 遍历定理"></a>2.4.4 遍历定理</h5><p>定理4（遍历定理）设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，状态空间为 $\mathcal{S}$, 若马尔可夫链 $X$ 是不可约、非周期且正常返的, 则该马尔可夫链有唯一平稳分布 $\pi=\left(\pi</em>{1}, \pi_{2}, \cdots\right)^{\mathrm{T}}$, 并且转移概率的极限分布是马尔可夫链的平稳分布</p>
<script type="math/tex; mode=display">
\begin{equation*}
\lim _{t \rightarrow \infty} P\left(X_{t}=i \mid X_{0}=j\right)=\pi_{i}, \quad i=1,2, \cdots ; \quad j=1,2, \cdots
\end{equation*}</script><p>若 $f(X)$ 是定义在状态空间上的函数, $E_{\pi}[|f(X)|]&lt;\infty$, 则</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left\{\hat{f}_{t} \rightarrow E_{\pi}[f(X)]\right\}=1
\end{equation*}</script><p>这里</p>
<script type="math/tex; mode=display">
\hat{f}_{t}=\frac{1}{t} \sum_{s=1}^{t} f\left(x_{s}\right)</script><p>$E<em>{\pi}[f(X)]=\sum</em>{i} f(i) \pi<em>{i}$ 是 $f(X)$ 关于平稳分布 $\pi=\left(\pi</em>{1}, \pi_{2}, \cdots\right)^{\mathrm{T}}$ 的数学期望，式 (19.26) 表示</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{f}_{t} \rightarrow E_{\pi}[f(X)], \quad t \rightarrow \infty
\end{equation*}</script><p>几乎处处成立或以概率 1 成立。</p>
<p>遍历定理的直观解释：满足相应条件的马尔可夫链，当时间趋于无穷时，马尔可夫链的状态分布趋近于平稳分布，随机变量的函数的样本均值以概率 1 收玫于该函数的数学期望。样本均值可以认为是时间均值，而数学期望是空间均值。遍历定理实际表述了遍历性的含义：当时间趋于无穷时，时间均值等于空间均值。遍历定理的三个条件：不可约、非周期、正常返，保证了当时间趋于无穷时达到任意一个状态的概率不为 0 。</p>
<p>理论上并不知道经过多少次迭代，马尔可夫链的状态分布才能接近于平稳分布，在实际应用遍历定理时，取一个足够大的整数 $m$ ，经过 $m$ 次迭代之后认为状态分布就是平稳分布, 这时计算从第 $m+1$ 次迭代到第 $n$ 次迭代的均值, 即</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{E} f=\frac{1}{n-m} \sum_{i=m+1}^{n} f\left(x_{i}\right)
\end{equation*}</script><p>称为遍历均值。</p>
<h5 id="2-4-5-可逆马尔可夫链"><a href="#2-4-5-可逆马尔可夫链" class="headerlink" title="2.4.5 可逆马尔可夫链"></a>2.4.5 可逆马尔可夫链</h5><p>定义6（可逆马尔可夫链） 设有马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$ ，状态空间为 $\mathcal{S}$ ，转移概率矩阵为 $P$ ，如果有状态分布 $\pi=\left(\pi</em>{1}, \pi_{2}, \cdots\right)^{\mathrm{T}}$ ，对于任意状态 $i, j \in \mathcal{S}$, 对任意一个时刻 $t$ 满足</p>
<script type="math/tex; mode=display">
\begin{equation*}
P\left(X_{t}=i \mid X_{t-1}=j\right) \pi_{j}=P\left(X_{t-1}=j \mid X_{t}=i\right) \pi_{i}, \quad i, j=1,2, \cdots
\end{equation*}</script><p>或简写为</p>
<script type="math/tex; mode=display">
\begin{equation*}
p_{j i} \pi_{j}=p_{i j} \pi_{i}, \quad i, j=1,2, \cdots
\end{equation*}</script><p>则称此马尔可夫链 $X$ 为可逆马尔可夫链（reversible Markov chain），式（19.30）称为细致平衡方程（detailed balance equation）。</p>
<p>直观上，如果有可逆的马尔可夫链，那么以该马尔可夫链的平稳分布作为初始分布, 进行随机状态转移, 无论是面向未来还是面向过去, 任何一个时刻的状态分布都是该平稳分布。例 19.3 中的马尔可夫链是可逆的，例 19.8 中的马尔可夫链是不可逆的。</p>
<p>定理5 （细致平衡方程）满足细致平衡方程的状态分布 $\pi$ 就是该马尔可夫链的平稳分布。即</p>
<script type="math/tex; mode=display">
P \pi=\pi</script><p>证明 事实上</p>
<script type="math/tex; mode=display">
\begin{equation*}
(P \pi)_{i}=\sum_{j} p_{i j} \pi_{j}=\sum_{j} p_{j i} \pi_{i}=\pi_{i} \sum_{j} p_{j i}=\pi_{i}, \quad i=1,2, \cdots
\end{equation*}</script><p>定理5 说明，可逆马尔可夫链一定有唯一平稳分布，给出了一个马尔可夫链有平稳分布的充分条件 (不是必要条件)。也就是说，可逆马尔可夫链满足遍历定理 4的条件。</p>
<h3 id="3-马氏链蒙特卡洛"><a href="#3-马氏链蒙特卡洛" class="headerlink" title="3. 马氏链蒙特卡洛"></a>3. 马氏链蒙特卡洛</h3><h4 id="3-1-思想"><a href="#3-1-思想" class="headerlink" title="3.1 思想"></a>3.1 思想</h4><p>假设目标是对一个概率分布进行随机抽样，或者是求函数关于该概率分布的数学期望。可以采用传统的蒙特卡罗法，如接受-拒绝法、重要性抽样法，也可以使用马尔可夫链蒙特卡罗法。马尔可夫链蒙特卡罗法更适合于<strong>随机变量是多元的、密度函数是非标准形式的、随机变量各分量不独立</strong>等情况。</p>
<p>假设多元随机变量 $x$, 满足 $x \in \mathcal{X}$, 其概率密度函数为 $p(x), f(x)$ 为定义在 $x \in \mathcal{X}$ 上的函数, 目标是获得概率分布 $p(x)$ 的样本集合, 以及求函数 $f(x)$ 的数学期望 $E_{p(x)}[f(x)]$ 。</p>
<p>应用 MCMC 解决这个问题。基本想法是：在随机变量 $x$ 的状态空间 $\mathcal{S}$ 上定义一个满足遍历定理的马尔可夫链 $X=\left{X<em>{0}, X</em>{1}, \cdots, X<em>{t}, \cdots\right}$, 使其平稳分布就是抽样的目标分布 $p(x)$ 。然后在这个马尔可夫链上进行随机游走，每个时刻得到一个样本。根据遍历定理, 当时间趋于无穷时, 样本的分布趋近平稳分布, 样本的函数均值趋近函数的数学期望。所以，当时间足够长时（时刻大于某个正整数 $m$ ）,在之后的时间（时刻小于等于某个正整数 $n, n&gt;m$ ）里随机游走得到的样本集合 $\left{x</em>{m+1}, x<em>{m+2}, \cdots, x</em>{n}\right}$ 就是目标概率分布的抽样结果，得到的函数均值（遍历均值）就是要计算的数学期望值:</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{E} f=\frac{1}{n-m} \sum_{i=m+1}^{n} f\left(x_{i}\right)
\end{equation*}</script><p>到时刻 $m$ 为止的时间段称为燃烧期。</p>
<p>如何构建具体的马尔可夫链成为这个方法的关键。连续变量的时候, 需要定义转移核函数；离散变量的时候，需要定义转移矩阵。一个方法是定义特殊的转移核函数或者转移矩阵, 构建可逆马尔可夫链, 这样可以保证遍历定理成立。常用的马尔可夫链蒙特卡罗法有 Metropolis-Hastings 算法、吉布斯抽样。</p>
<p>由于这个马尔可夫链满足遍历定理, 随机游走的起始点并不影响得到的结果, 即从不同的起始点出发，都会收敛到同一平稳分布。</p>
<p>MCMC 的收敛性的判断通常是经验性的，比如，在马尔可夫链上进行随机游走，检验遍历均值是否收玫。具体地，每隔一段时间取一次样本，得到多个样本以后, 计算遍历均值, 当计算的均值稳定后, 认为马尔可夫链已经收玫。再比如，在马尔可夫链上并行进行多个随机游走，比较各个随机游走的遍历均值是否接近一致。</p>
<p>马尔可夫链蒙特卡罗法中得到的样本序列，相邻的样本点是相关的，而不是独立的。因此，在需要独立样本时，可以在该样本序列中再次进行随机抽样，比如每隔一段时间取一次样本，将这样得到的子样本集合作为独立样本集合。</p>
<p>马尔可夫链蒙特卡罗法比接受-拒绝法更容易实现，因为只需要定义马尔可夫链，而不需要定义建议分布。一般来说马尔可夫链蒙特卡罗法比接受-拒绝法效率更高, 没有大量被拒绝的样本，虽然燃烧期的样本也要抛弃。</p>
<h4 id="3-2-基本步骤"><a href="#3-2-基本步骤" class="headerlink" title="3.2 基本步骤"></a>3.2 基本步骤</h4><p>根据上面的讨论, 可以将马尔可夫链蒙特卡罗法概括为以下三步:<br>(1) 首先, 在随机变量 $x$ 的状态空间 $\mathcal{S}$ 上构造一个满足遍历定理的马尔可夫链,使其平稳分布为目标分布 $p(x)$;<br>(2) 从状态空间的某一点 $x<em>{0}$ 出发, 用构造的马尔可夫链进行随机游走, 产生样本序列 $x</em>{0}, x<em>{1}, \cdots, x</em>{t}, \cdots$ 。<br>(3) 应用马尔可夫链的遍历定理, 确定正整数 $m$ 和 $n,(m&lt;n)$, 得到样本集合 $\left{x<em>{m+1}, x</em>{m+2}, \cdots, x_{n}\right}$, 求得函数 $f(x)$ 的均值 (遍历均值)</p>
<script type="math/tex; mode=display">
\begin{equation*}
\hat{E} f=\frac{1}{n-m} \sum_{i=m+1}^{n} f\left(x_{i}\right) \tag{19.33}
\end{equation*}</script><p>就是马尔可夫链蒙特卡罗法的计算公式。<br>这里有几个重要问题:</p>
<ul>
<li>如何定义马尔可夫链, 保证马尔可夫链蒙特卡罗法的条件成立。</li>
<li>如何确定收玫步数 $m$, 保证样本抽样的无偏性。</li>
<li>如何确定迭代步数 $n$, 保证遍历均值计算的精度。</li>
</ul>
<h4 id="3-3-MCMC-与统计学习"><a href="#3-3-MCMC-与统计学习" class="headerlink" title="3.3 MCMC 与统计学习"></a>3.3 MCMC 与统计学习</h4><p>马尔可夫链蒙特卡罗法在统计学习, 特别是贝叶斯学习中, 起着重要的作用。主要是因为马尔可夫链蒙特卡罗法可以用在概率模型的学习和推理上。</p>
<p>假设观测数据由随机变量 $y \in \mathcal{Y}$ 表示, 模型由随机变量 $x \in \mathcal{X}$ 表示, 贝叶斯学习通过贝叶斯定理计算给定数据条件下模型的后验概率, 并选择后验概率最大的模型。后验概率</p>
<script type="math/tex; mode=display">
\begin{equation*}
p(x \mid y)=\frac{p(x) p(y \mid x)}{\int_{\mathcal{X}} p\left(y \mid x^{\prime}\right) p\left(x^{\prime}\right) \mathrm{d} x^{\prime}}
\end{equation*}</script><p>贝叶斯学习中经常需要进行三种积分运算：归范化 (normalization)、边缘化 (marginalization)、数学期望 (expectation)。后验概率计算中需要归范化计算:</p>
<script type="math/tex; mode=display">
\begin{equation*}
\int_{\mathcal{X}} p\left(y \mid x^{\prime}\right) p\left(x^{\prime}\right) \mathrm{d} x^{\prime} \tag{19.35}
\end{equation*}</script><p>如果有隐变量 $z \in \mathcal{Z}$, 后验概率的计算需要边缘化计算:</p>
<script type="math/tex; mode=display">
\begin{equation*}
p(x \mid y)=\int_{\mathcal{Z}} p(x, z \mid y) \mathrm{d} z \tag{19.36}
\end{equation*}</script><p>如果有一个函数 $f(x)$, 可以计算该函数的关于后验概率分布的数学期望:</p>
<script type="math/tex; mode=display">
\begin{equation*}
E_{P(x \mid y)}[f(x)]=\int_{\mathcal{X}} f(x) p(x \mid y) \mathrm{d} x \tag{19.37}
\end{equation*}</script><p>当观测数据和模型都很复杂的时候, 以上的积分计算变得困难。马尔可夫链蒙特卡罗法为这些计算提供了一个通用的有效解决方案。</p>
<h3 id="4-M-H-算法"><a href="#4-M-H-算法" class="headerlink" title="4. M-H 算法"></a>4. M-H 算法</h3><p>本节叙述 Metropolis-Hastings 算法, 是马尔可夫链蒙特卡罗法的代表算法。</p>
<h4 id="4-1-基本原理"><a href="#4-1-基本原理" class="headerlink" title="4.1 基本原理"></a>4.1 基本原理</h4><h5 id="4-1-1-马尔可夫链"><a href="#4-1-1-马尔可夫链" class="headerlink" title="4.1.1 马尔可夫链"></a>4.1.1 马尔可夫链</h5><p>假设要抽样的概率分布为 $p(x)$ 。Metropolis-Hastings 算法采用转移核为 $p\left(x, x^{\prime}\right)$的马尔可夫链:</p>
<script type="math/tex; mode=display">
\begin{equation*}
p\left(x, x^{\prime}\right)=q\left(x, x^{\prime}\right) \alpha\left(x, x^{\prime}\right)
\end{equation*}</script><p>其中 $q\left(x, x^{\prime}\right)$ 和 $\alpha\left(x, x^{\prime}\right)$ 分别称为建议分布（proposal distribution）和接受分布 (acceptance distribution) 。</p>
<p>建议分布 $q\left(x, x^{\prime}\right)$ 是另一个马尔可夫链的转移核, 并且 $q\left(x, x^{\prime}\right)$ 是不可约的, 即其概率值恒不为 0 , 同时是一个容易抽样的分布。接受分布 $\alpha\left(x, x^{\prime}\right)$ 是</p>
<script type="math/tex; mode=display">
\begin{equation*}
\alpha\left(x, x^{\prime}\right)=\min \left\{1, \frac{p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)}{p(x) q\left(x, x^{\prime}\right)}\right\}
\end{equation*}</script><p>这时, 转移核 $p\left(x, x^{\prime}\right)$ 可以写成</p>
<script type="math/tex; mode=display">
p\left(x, x^{\prime}\right)= \begin{cases}q\left(x, x^{\prime}\right), & p\left(x^{\prime}\right) q\left(x^{\prime}, x\right) \geqslant p(x) q\left(x, x^{\prime}\right)  \\ q\left(x^{\prime}, x\right) \frac{p\left(x^{\prime}\right)}{p(x)}, & p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)<p(x) q\left(x, x^{\prime}\right)\end{cases}</script><p>转移核为 $p\left(x, x^{\prime}\right)$ 的马尔可夫链上的随机游走以以下方式进行。如果在时刻<br>$(t-1)$ 处于状态 $x$, 即 $x_{t-1}=x$, 则先按建议分布 $q\left(x, x^{\prime}\right)$ 抽样产生一个候选状态 $x^{\prime}$,然后按照接受分布 $\alpha\left(x, x^{\prime}\right)$ 抽样决定是否接受状态 $x^{\prime}$ 。以概率 $\alpha\left(x, x^{\prime}\right)$ 接受 $x^{\prime}$ ，决定时刻 $t$ 转移到状态 $x^{\prime}$ ，而以概率 $1-\alpha\left(x, x^{\prime}\right)$ 拒绝 $x^{\prime}$ ，决定时刻 $t$ 仍停留在状态 $x$ 。具体地，从区间 $(0,1)$ 上的均匀分布中抽取一个随机数 $u$ ，决定时刻 $t$ 的状态。</p>
<script type="math/tex; mode=display">
x_{t}= \begin{cases}x^{\prime}, & u \leqslant \alpha\left(x, x^{\prime}\right) \\ x, & u>\alpha\left(x, x^{\prime}\right)\end{cases}</script><p>可以证明, 转移核为 $p\left(x, x^{\prime}\right)$ 的马尔可夫链是可逆马尔可夫链（满足遍历定理），其平稳分布就是 $p(x)$ ，即要抽样的目标分布。也就是说这是马尔可夫链蒙特卡罗法的一个具体实现。</p>
<p>定理 6 由转移核 (19.38) (19.40) 构成的马尔可夫链是可逆的, 即</p>
<script type="math/tex; mode=display">
\begin{equation*}
p(x) p\left(x, x^{\prime}\right)=p\left(x^{\prime}\right) p\left(x^{\prime}, x\right)
\end{equation*}</script><p>并且 $p(x)$ 是该马尔可夫链的平稳分布。</p>
<p>证明 若 $x=x^{\prime}$ ，则式（19.41）显然成立。<br>设 $x \neq x^{\prime}$ ，则</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(x) p\left(x, x^{\prime}\right) & =p(x) q\left(x, x^{\prime}\right) \min \left\{1, \frac{p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)}{p(x) q\left(x, x^{\prime}\right)}\right\} \\
& =\min \left\{p(x) q\left(x, x^{\prime}\right), p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)\right\} \\
& =p\left(x^{\prime}\right) q\left(x^{\prime}, x\right) \min \left\{\frac{p(x) q\left(x, x^{\prime}\right)}{p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)}, 1\right\} \\
& =p\left(x^{\prime}\right) p\left(x^{\prime}, x\right)
\end{aligned}</script><p>式 (19.41) 成立。<br>由式 (19.41) 知,</p>
<script type="math/tex; mode=display">
\begin{aligned}
\int p(x) p\left(x, x^{\prime}\right) \mathrm{d} x & =\int p\left(x^{\prime}\right) p\left(x^{\prime}, x\right) \mathrm{d} x \\
& =p\left(x^{\prime}\right) \int p\left(x^{\prime}, x\right) \mathrm{d} x \\
& =p\left(x^{\prime}\right)
\end{aligned}</script><p>根据平稳分布的定义 (19.21), $p(x)$ 是马尔可夫链的平稳分布。</p>
<h5 id="4-1-2-建议分布"><a href="#4-1-2-建议分布" class="headerlink" title="4.1.2 建议分布"></a>4.1.2 建议分布</h5><p>建议分布 $q\left(x, x^{\prime}\right)$ 有多种可能的形式, 这里介绍两种常用形式。<br>第一种形式，假设建议分布是对称的，即对任意的 $x$ 和 $x^{\prime}$ 有</p>
<script type="math/tex; mode=display">
\begin{equation*}
q\left(x, x^{\prime}\right)=q\left(x^{\prime}, x\right) \tag{19.42}
\end{equation*}</script><p>这样的建议分布称为 Metropolis 选择, 也是 Metropolis-Hastings 算法最初采用的建议分布。这时, 接受分布 $\alpha\left(x, x^{\prime}\right)$ 简化为</p>
<script type="math/tex; mode=display">
\begin{equation*}
\alpha\left(x, x^{\prime}\right)=\min \left\{1, \frac{p\left(x^{\prime}\right)}{p(x)}\right\} \tag{19.43}
\end{equation*}</script><p>Metropolis 选择的一个特例是 $q\left(x, x^{\prime}\right)$ 取条件概率分布 $p\left(x^{\prime} \mid x\right)$ ，定义为多元正态分布, 其均值是 $x$, 其协方差矩阵是常数矩阵。</p>
<p>Metropolis 选择的另一个特例是令 $q\left(x, x^{\prime}\right)=q\left(\left|x-x^{\prime}\right|\right)$, 这时算法称为随机游走 Metropolis 算法。例如，</p>
<script type="math/tex; mode=display">
q\left(x, x^{\prime}\right) \propto \exp \left(-\frac{\left(x^{\prime}-x\right)^{2}}{2}\right)</script><p>Metropolis 选择的特点是当 $x^{\prime}$ 与 $x$ 接近时, $q\left(x, x^{\prime}\right)$ 的概率值高, 否则 $q\left(x, x^{\prime}\right)$ 的概率值低。状态转移在附近点的可能性更大。</p>
<p>第二种形式称为独立抽样。假设 $q\left(x, x^{\prime}\right)$ 与当前状态 $x$ 无关, 即 $q\left(x, x^{\prime}\right)=q\left(x^{\prime}\right)$ 。建议分布的计算按照 $q\left(x^{\prime}\right)$ 独立抽样进行。此时, 接受分布 $\alpha\left(x, x^{\prime}\right)$ 可以写成</p>
<script type="math/tex; mode=display">
\begin{equation*}
\alpha\left(x, x^{\prime}\right)=\min \left\{1, \frac{w\left(x^{\prime}\right)}{w(x)}\right\} \tag{19.44}
\end{equation*}</script><p>其中 $w\left(x^{\prime}\right)=p\left(x^{\prime}\right) / q\left(x^{\prime}\right), w(x)=p(x) / q(x)$ 。<br>独立抽样实现简单, 但可能收玫速度慢, 通常选择接近目标分布 $p(x)$ 的分布作为建议分布 $q(x)$ 。</p>
<h5 id="4-1-3-满条件分布"><a href="#4-1-3-满条件分布" class="headerlink" title="4.1.3 满条件分布"></a>4.1.3 满条件分布</h5><p>马尔可夫链蒙特卡罗法的目标分布通常是多元联合概率分布 $p(x)=p\left(x<em>{1}, x</em>{2}, \cdots\right.$, $\left.x<em>{k}\right)$, 其中 $x=\left(x</em>{1}, x<em>{2}, \cdots, x</em>{k}\right)^{\mathrm{T}}$ 为 $k$ 维随机变量。如果条件概率分布 $p\left(x<em>{I} \mid x</em>{-I}\right)$ 中所有 $k$ 个变量全部出现，其中 $x<em>{I}=\left{x</em>{i}, i \in I\right}, x<em>{-I}=\left{x</em>{i}, i \notin I\right}, I \subset K={1,2, \cdots, k}$ ，那么称这种条件概率分布为满条件分布（full conditional distribution）。</p>
<p>满条件分布有以下性质：对任意的 $x, x^{\prime} \in \mathcal{X}$ 和任意的 $I \subset K$ ，有</p>
<script type="math/tex; mode=display">
\begin{equation*}
p\left(x_{I} \mid x_{-I}\right)=\frac{p(x)}{\int p(x) \mathrm{d} x_{I}} \propto p(x) \tag{19.45}
\end{equation*}</script><p>而且, 对任意的 $x, x^{\prime} \in \mathcal{X}$ 和任意的 $I \subset K$ ，有</p>
<script type="math/tex; mode=display">
\begin{equation*}
\frac{p\left(x_{I}^{\prime} \mid x_{-I}^{\prime}\right)}{p\left(x_{I} \mid x_{-I}\right)}=\frac{p\left(x^{\prime}\right)}{p(x)} \tag{19.46}
\end{equation*}</script><p>Metropolis-Hastings 算法中, 可以利用性质 (19.46), 简化计算, 提高计算效率。具体地，通过满条件分布概率的比 $\frac{p\left(x<em>{I}^{\prime} \mid x</em>{-I}^{\prime}\right)}{p\left(x<em>{I} \mid x</em>{-I}\right)}$ 计算联合概率的比 $\frac{p\left(x^{\prime}\right)}{p(x)}$ ，而前者更容易计算。</p>
<h4 id="4-2-Metropolis-Hastings-算法"><a href="#4-2-Metropolis-Hastings-算法" class="headerlink" title="4.2 Metropolis-Hastings 算法"></a>4.2 Metropolis-Hastings 算法</h4><p>输入：抽样的目标分布的密度函数 $p(x)$ ，函数 $f(x)$ ；</p>
<p>输出: $p(x)$ 的随机样本 $x<em>{m+1}, x</em>{m+2}, \cdots, x<em>{n}$, 函数样本均值 $f</em>{m n}$ ；<br>参数：收玫步数 $m$ ，迭代步数 $n$ 。<br>(1) 任意选择一个初始值 $x<em>{0}$<br>(2) 对 $i=1,2, \cdots, n$ 循环执行<br>（a）设状态 $x</em>{i-1}=x$, 按照建议分布 $q\left(x, x^{\prime}\right)$ 随机抽取一个候选状态 $x^{\prime}$ 。<br>（b）计算接受概率</p>
<script type="math/tex; mode=display">
\alpha\left(x, x^{\prime}\right)=\min \left\{1, \frac{p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)}{p(x) q\left(x, x^{\prime}\right)}\right\}</script><p>（c）从区间 $(0,1)$ 中按均匀分布随机抽取一个数 $u$ 。<br>若 $u \leqslant \alpha\left(x, x^{\prime}\right)$, 则状态 $x<em>{i}=x^{\prime}$; 否则, 状态 $x</em>{i}=x$ 。<br>(3) 得到样本集合 $\left{x<em>{m+1}, x</em>{m+2}, \cdots, x_{n}\right}$</p>
<p>计算</p>
<script type="math/tex; mode=display">
f_{m n}=\frac{1}{n-m} \sum_{i=m+1}^{n} f\left(x_{i}\right)</script><h4 id="4-3-单分量-Metropolis-Hastings-算法"><a href="#4-3-单分量-Metropolis-Hastings-算法" class="headerlink" title="4.3 单分量 Metropolis-Hastings 算法"></a>4.3 单分量 Metropolis-Hastings 算法</h4><p>在 Metropolis-Hastings 算法中，通常需要对多元变量分布进行抽样，有时对多元变量分布的抽样是困难的。可以对多元变量的每一变量的条件分布依次分别进行抽样, 从而实现对整个多元变量的一次抽样, 这就是单分量 Metropolis-Hastings (singlecomponent Metropolis-Hastings）算法。</p>
<p>假设马尔可夫链的状态由 $k$ 维随机变量表示</p>
<script type="math/tex; mode=display">
x=\left(x_{1}, x_{2}, \cdots, x_{k}\right)^{\mathrm{T}}</script><p>其中 $x_{j}$ 表示随机变量 $x$ 的第 $j$ 个分量, $j=1,2, \cdots, k$, 而 $x^{(i)}$ 表示马尔可夫链在时刻 $i$ 的状态</p>
<script type="math/tex; mode=display">
x^{(i)}=\left(x_{1}^{(i)}, x_{2}^{(i)}, \cdots, x_{k}^{(i)}\right)^{\mathrm{T}}, \quad i=1,2, \cdots, n</script><p>其中 $x_{j}^{(i)}$ 是随机变量 $x^{(i)}$ 的第 $j$ 个分量， $j=1,2, \cdots, k$ 。<br>为了生成容量为 $n$ 的样本集合 $\left{x^{(1)}, x^{(2)}, \cdots, x^{(n)}\right}$ ～单分量 Metropolis-Hastings算法由下面的 $k$ 步迭代实现 Metropolis-Hastings 算法的一次迭代。</p>
<p>设在第 $(i-1)$ 次迭代结束时分量 $x<em>{j}$ 的取值为 $x</em>{j}^{(i-1)}$ ，在第 $i$ 次迭代的第 $j$ 步，</p>
<p>对分量 $x<em>{j}$ 根据 Metropolis-Hastings 算法更新, 得到其新的取值 $x</em>{j}^{(i)}$ 。首先, 由建议分布 $q\left(x<em>{j}^{(i-1)}, x</em>{j} \mid x<em>{-j}^{(i)}\right)$ 抽样产生分量 $x</em>{j}$ 的候选值 $x<em>{j}^{\prime(i)}$ ，这里 $x</em>{-j}^{(i)}$ 表示在第 $i$ 次迭代的第 $(j-1)$ 步后的 $x^{(i)}$ 除去 $x_{j}^{(i-1)}$ 的所有值, 即</p>
<script type="math/tex; mode=display">
x_{-j}^{(i)}=\left(x_{1}^{(i)}, \cdots, x_{j-1}^{(i)}, x_{j+1}^{(i-1)}, \cdots, x_{k}^{(i-1)}\right)^{\mathrm{T}}</script><p>其中分量 $1,2, \cdots, j-1$ 已经更新。然后, 按照接受概率</p>
<script type="math/tex; mode=display">
\begin{equation*}
\alpha\left(x_{j}^{(i-1)},{x^{\prime}}_{j}^{(i)} \mid x_{-j}^{(i)}\right)=\min \left\{1, \frac{p\left(x_{j}^{\prime(i)} \mid x_{-j}^{(i)}\right) q\left(_{j}^{\prime(i)}, x_{j}^{(i-1)} \mid x_{-j}^{(i)}\right)}{p\left(x_{j}^{(i-1)} \mid x_{-j}^{(i)}\right) q\left(x_{j}^{(i-1)}, x_{j}^{(i)} \mid x_{-j}^{(i)}\right)}\right\}
\end{equation*}</script><p>抽样决定是否接受候选值 $x^{\prime(i)}$ 。如果 ${x^{\prime}}<em>{j}^{(i)}$ 被接受, 则令 $x</em>{j}^{(i)}={x^{\prime}}<em>{j}^{(i)}$; 否则令 $x</em>{j}^{(i)}=$ $x_{j}^{(i-1)}$ 。其余分量在第 $j$ 步不改变。马尔可夫链的转移概率为</p>
<script type="math/tex; mode=display">
\begin{equation*}
p\left(x_{j}^{(i-1)}, x_{j}^{\prime(i)} \mid x_{-j}^{(i)}\right)=\alpha\left(x_{j}^{(i-1)},{x^{\prime}}_{j}^{(i)} \mid x_{-j}^{(i)}\right) q\left(x_{j}^{(i-1)}, x_{j}^{\prime(i)} \mid x_{-j}^{(i)}\right)
\end{equation*}</script><h3 id="5-吉布斯抽样"><a href="#5-吉布斯抽样" class="headerlink" title="5 吉布斯抽样"></a>5 吉布斯抽样</h3><p>本节叙述马尔可夫链蒙特卡罗法的常用算法吉布斯抽样, 可以认为是 MetropolisHastings 算法的特殊情况，但是更容易实现，因而被广泛使用。</p>
<h4 id="5-1-基本原理"><a href="#5-1-基本原理" class="headerlink" title="5.1 基本原理"></a>5.1 基本原理</h4><p>吉布斯抽样（Gibbs sampling）用于多元变量联合分布的抽样和估计 ${ }^{(1)}$ 。其基本做法是，从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列。可以证明这样的抽样过程是在一个马尔可夫链上的随机游走，每一个样本对应着马尔可夫链的状态，平稳分布就是目标的联合分布。整体成为一个马尔可夫链蒙特卡罗法，燃烧期之后的样本就是联合分布的随机样本。</p>
<p>假设多元变量的联合概率分布为 $p(x)=p\left(x<em>{1}, x</em>{2}, \cdots, x<em>{k}\right)$ 。吉布斯抽样从一个初始样本 $x^{(0)}=\left(x</em>{1}^{(0)}, x<em>{2}^{(0)}, \cdots, x</em>{k}^{(0)}\right)^{\mathrm{T}}$ 出发，不断进行迭代，每一次迭代得到联合分布的一个样本 $x^{(i)}=\left(x<em>{1}^{(i)}, x</em>{2}^{(i)}, \cdots, x_{k}^{(i)}\right)^{\mathrm{T}}$ 。最终得到样本序列 $\left{x^{(0)}, x^{(1)}, \cdots, x^{(n)}\right}$ 。</p>
<p>在每次迭代中，依次对 $k$ 个随机变量中的一个变量进行随机抽样。如果在第 $i$ 次迭代中，对第 $j$ 个变量进行随机抽样，那么抽样的分布是满条件概率分布 $p\left(x<em>{j} \mid x</em>{-j}^{(i)}\right)$ ，这里 $x_{-j}^{(i)}$ 表示第 $i$ 次迭代中，变量 $j$ 以外的其他变量。</p>
<p>设在第 $(i-1)$ 步得到样本 $\left(x<em>{1}^{(i-1)}, x</em>{2}^{(i-1)}, \cdots, x_{k}^{(i-1)}\right)^{\mathrm{T}}$ ，在第 $i$ 步，首先对第一个变量按照以下满条件概率分布随机抽样</p>
<script type="math/tex; mode=display">
p\left(x_{1} \mid x_{2}^{(t-1)}, \cdots, x_{k}^{(t-1)}\right)</script><p>得到 $x_{1}^{(i)}$, 之后依次对第 $j$ 个变量按照以下满条件概率分布随机抽样</p>
<script type="math/tex; mode=display">
p\left(x_{j} \mid x_{1}^{(i)}, \cdots, x_{j-1}^{(i)}, x_{j+1}^{(i-1)}, \cdots, x_{k}^{(i-1)}\right), \quad j=2, \cdots, k-1</script><p>得到 $x_{j}^{(i)}$ ，最后对第 $k$ 个变量按照以下满条件概率分布随机抽样</p>
<script type="math/tex; mode=display">
p\left(x_{k} \mid x_{1}^{(i)}, \cdots, x_{k-1}^{(i)}\right)</script><p>得到 $x<em>{k}^{(i)}$, 于是得到整体样本 $x^{(i)}=\left(x</em>{1}^{(i)}, x<em>{2}^{(i)}, \cdots, x</em>{k}^{(i)}\right)^{\mathrm{T}}$ 。<br>吉布斯抽样是单分量 Metropolis-Hastings 算法的特殊情况。定义建议分布是当前变量 $x_{j}, j=1,2, \cdots, k$ 的满条件概率分布</p>
<script type="math/tex; mode=display">
\begin{equation*}
q\left(x, x^{\prime}\right)=p\left(x_{j}^{\prime} \mid x_{-j}\right) \tag{19.49}
\end{equation*}</script><p>这时， 接受概率 $\alpha=1$ ，</p>
<script type="math/tex; mode=display">
\begin{align*}
\alpha\left(x, x^{\prime}\right) & =\min \left\{1, \frac{p\left(x^{\prime}\right) q\left(x^{\prime}, x\right)}{p(x) q\left(x, x^{\prime}\right)}\right\} \\
& =\min \left\{1, \frac{p\left(x^{\prime}{ }_{-j}\right) p\left(x^{\prime}{ }_{j} \mid x^{\prime}{ }_{-j}\right) p\left(x_{j} \mid x^{\prime}{ }_{-j}\right)}{p\left(x_{-j}\right) p\left(x_{j} \mid x_{-j}\right) p\left(x^{\prime}{ }_{j} \mid x_{-j}\right)}\right\}=1
\end{align*}</script><p><sup><a href="#fn_2" id="reffn_2">2</a></sup>这里用到 $p\left(x<em>{-j}\right)=p\left(x^{\prime}{ }</em>{-j}\right)$ 和 $p\left(\cdot \mid x<em>{-j}\right)=p\left(\cdot \mid x^{\prime}{ }</em>{-j}\right)$ 。<br>转移核就是满条件概率分布</p>
<script type="math/tex; mode=display">
\begin{equation*}
p\left(x, x^{\prime}\right)=p\left(x^{\prime}{ }_{j} \mid x_{-j}\right)
\end{equation*}</script><p>也就是说依次按照单变量的满条件概率分布 $p\left(x^{\prime}{ }<em>{j} \mid x</em>{-j}\right)$ 进行随机抽样, 就能实现单分量 Metropolis-Hastings 算法。吉布斯抽样对每次抽样的结果都接受，没有拒绝，这一点和一般的 Metropolis-Hastings 算法不同。</p>
<p>这里，假设满条件概率分布 $p\left(x^{\prime}{ }<em>{j} \mid x</em>{-j}\right)$ 不为 0 ，即马尔可夫链是不可约的。</p>
<h4 id="5-2-吉布斯抽样算法"><a href="#5-2-吉布斯抽样算法" class="headerlink" title="5.2 吉布斯抽样算法"></a>5.2 吉布斯抽样算法</h4><p>输入：目标概率分布的密度函数 $p(x)$ ，函数 $f(x)$ ；<br>输出: $p(x)$ 的随机样本 $x<em>{m+1}, x</em>{m+2}, \cdots, x<em>{n}$, 函数样本均值 $f</em>{m n}$ ；<br>参数：收玫步数 $m$ ，迭代步数 $n$ 。<br>（1）初始化。给出初始样本 $x^{(0)}=\left(x<em>{1}^{(0)}, x</em>{2}^{(0)}, \cdots, x_{k}^{(0)}\right)^{\mathrm{T}}$ 。<br>(2) 对 $i$ 循环执行</p>
<p>设第 $(i-1)$ 次迭代结束时的样本为 $x^{(i-1)}=\left(x<em>{1}^{(i-1)}, x</em>{2}^{(i-1)}, \cdots, x<em>{k}^{(i-1)}\right)^{\mathrm{T}}$, 则第 $i$次迭代进行如下几步操作:<br>(（1）由满条件分布 $p\left(x</em>{1} \mid x<em>{2}^{(i-1)}, \cdots, x</em>{k}^{(i-1)}\right)$ 抽取 $x<em>{1}^{(i)}$<br>（ j ）由满条件分布 $p\left(x</em>{j} \mid x<em>{1}^{(i)}, \cdots, x</em>{j-1}^{(i)}, x<em>{j+1}^{(i-1)}, \cdots, x</em>{k}^{(i-1)}\right)$ 抽取 $x<em>{j}^{(i)}$ $\vdots$<br>( k ) 由满条件分布 $p\left(x</em>{k} \mid x<em>{1}^{(i)}, \cdots, x</em>{k-1}^{(i)}\right)$ 抽取 $x<em>{k}^{(i)}$得到第 $i$ 次迭代值 $x^{(i)}=\left(x</em>{1}^{(i)}, x<em>{2}^{(i)}, \cdots, x</em>{k}^{(i)}\right)^{\mathrm{T}}$ 。<br>(3) 得到样本集合</p>
<script type="math/tex; mode=display">
\left\{x^{(m+1)}, x^{(m+2)}, \cdots, x^{(n)}\right\}</script><p>(4) 计算</p>
<script type="math/tex; mode=display">
f_{m n}=\frac{1}{n-m} \sum_{i=m+1}^{n} f\left(x^{(i)}\right)</script><p>单分量 Metropolis-Hastings 算法和吉布斯抽样的不同之处在于，</p>
<ul>
<li>在前者算法中，抽样会在样本点之间移动，但其间可能在某一些样本点上停留（由于抽样被拒绝）；</li>
<li>而在后者算法中，抽样会在样本点之间持续移动。</li>
</ul>
<p>吉布斯抽样适合于满条件概率分布容易抽样的情况，而单分量 MetropolisHastings 算法适合于满条件概率分布不容易抽样的情况，这时使用容易抽样的条件分布作建议分布。</p>
<h4 id="5-3-抽样计算"><a href="#5-3-抽样计算" class="headerlink" title="5.3 抽样计算"></a>5.3 抽样计算</h4><p>吉布斯抽样中需要对满条件概率分布进行重复多次抽样。可以利用概率分布的性质提高抽样的效率。下面以贝叶斯学习为例介绍这个技巧。</p>
<p>设 $y$ 表示观测数据， $\alpha, \theta, z$ 分别表示超参数、模型参数、未观测数据， $x=(\alpha, \theta, z)$ ，如图 19.12 所示。贝叶斯学习的目的是估计后验概率分布 $p(x \mid y)$, 求后验概率最大的模型。</p>
<script type="math/tex; mode=display">
\begin{equation*}
p(x \mid y)=p(\alpha, \theta, z \mid y) \propto p(z, y \mid \theta) p(\theta \mid \alpha) p(\alpha)
\end{equation*}</script><p>式中 $p(\alpha)$ 是超参数分布, $p(\theta \mid \alpha)$ 是先验分布, $p(z, y \mid \theta)$ 是完全数据的分布。<br>现在用吉布斯抽样估计 $p(x \mid y)$ ，其中 $y$ 已知， $x=(\alpha, \theta, z)$ 未知。吉布斯抽样中各个变量 $\alpha, \theta, z$ 的满条件分布有以下关系：</p>
<script type="math/tex; mode=display">
\begin{align*}
& p\left(\alpha_{i} \mid \alpha_{-i}, \theta, z, y\right) \propto p(\theta \mid \alpha) p(\alpha)  \\
& p\left(\theta_{j} \mid \theta_{-j}, \alpha, z, y\right) \propto p(z, y \mid \theta) p(\theta \mid \alpha)  \\
& p\left(z_{k} \mid z_{-k}, \alpha, \theta, y\right) \propto p(z, y \mid \theta)
\end{align*}</script><p>其中 $\alpha<em>{-i}$ 表示变量 $\alpha</em>{i}$ 以外的所有变量， $\theta<em>{-j}$ 和 $z</em>{-k}$ 类似。满条件概率分布与若干条件概率分布的乘积成正比，各个条件概率分布只由少量的相关变量组成（图模型中相邻结点表示的变量）。所以，依满条件概率分布的抽样可以通过依这些条件概率分布的乘积的抽样进行。这样可以大幅减少抽样的计算复杂度，因为计算只涉及部分变量。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">LiuJT</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/10/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC19%E7%AB%A0%20MCMC%E6%96%B9%E6%B3%95/">http://example.com/2024/10/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC19%E7%AB%A0%20MCMC%E6%96%B9%E6%B3%95/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">LiuJT's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/08/28/K8FcuStCQYsTV4A.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/10/11/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC18%E7%AB%A0%20%E6%A6%82%E7%8E%87%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90/" title="统计学习方法--第18章 概率潜在语义分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/6xBSQotbm7N13Kn.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">统计学习方法--第18章 概率潜在语义分析</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/08/29/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95--%E7%AC%AC2%E7%AB%A0%20%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="统计学习方法--第2章 感知机"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/K8FcuStCQYsTV4A.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-29</div><div class="title">统计学习方法--第2章 感知机</div></div></a></div><div><a href="/2024/08/30/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95--%E7%AC%AC4%E7%AB%A0%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" title="统计学习方法--第4章 朴素贝叶斯"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/6xBSQotbm7N13Kn.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-30</div><div class="title">统计学习方法--第4章 朴素贝叶斯</div></div></a></div><div><a href="/2024/08/30/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95--%E7%AC%AC3%E7%AB%A0%20k%E8%BF%91%E9%82%BB%E6%B3%95/" title="统计学习方法--第3章 k近邻法"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/LEAbKcnumgeXP8V.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-30</div><div class="title">统计学习方法--第3章 k近邻法</div></div></a></div><div><a href="/2024/09/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95--%E7%AC%AC5%E7%AB%A0%20%E5%86%B3%E7%AD%96%E6%A0%91/" title="统计学习方法--第5章 决策树"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/ZHLKYkGh4gcCfu6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-12</div><div class="title">统计学习方法--第5章 决策树</div></div></a></div><div><a href="/2024/09/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E7%AC%AC6%E7%AB%A0%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%92%8C%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" title="统计学习方法--第6章 逻辑回归和最大熵模型"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/7ISX9YV1U4Fbp3n.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-15</div><div class="title">统计学习方法--第6章 逻辑回归和最大熵模型</div></div></a></div><div><a href="/2024/08/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95--%E7%AC%AC1%E7%AB%A0%20%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="统计学习方法--第1章 统计学习及监督学习概论"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/uDX9laHIOJK6oMv.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-27</div><div class="title">统计学习方法--第1章 统计学习及监督学习概论</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/08/28/WOMi84ksFx3dGY1.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">LiuJT</div><div class="author-info__description">统计学习笔记&论文阅读</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/TJLJT0929"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/TJLJT0929" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1007582793@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎大家来到我的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B"><span class="toc-text">1. 蒙特卡洛</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7"><span class="toc-text">1.1 随机抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-1-%E7%9B%B4%E6%8E%A5%E6%8A%BD%E6%A0%B7"><span class="toc-text">1.1.1 直接抽样</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-2-%E6%8E%A5%E5%8F%97%E6%8B%92%E7%BB%9D%E6%8A%BD%E6%A0%B7"><span class="toc-text">1.1.2 接受拒绝抽样</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-3-%E9%87%8D%E8%A6%81%E6%80%A7%E6%8A%BD%E6%A0%B7"><span class="toc-text">1.1.3 重要性抽样</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E5%BA%94%E7%94%A8"><span class="toc-text">1.2 蒙特卡洛应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B%E4%BC%B0%E8%AE%A1"><span class="toc-text">1.2.1 数学期望估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E7%A7%AF%E5%88%86%E8%AE%A1%E7%AE%97"><span class="toc-text">1.2.2 积分计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%A9%AC%E6%B0%8F%E9%93%BE"><span class="toc-text">2. 马氏链</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E5%AE%9A%E4%B9%89"><span class="toc-text">2.1 定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E7%A6%BB%E6%95%A3%E7%8A%B6%E6%80%81%E9%A9%AC%E6%B0%8F%E9%93%BE"><span class="toc-text">2.2 离散状态马氏链</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-%E8%BD%AC%E7%A7%BB%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%92%8C%E7%8A%B6%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-text">2.2.1 转移概率矩阵和状态分布</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-2-%E5%B9%B3%E7%A8%B3%E5%88%86%E5%B8%83"><span class="toc-text">2.2.2 平稳分布</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E8%BF%9E%E7%BB%AD%E7%8A%B6%E6%80%81%E9%A9%AC%E6%B0%8F%E9%93%BE"><span class="toc-text">2.3 连续状态马氏链</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E9%A9%AC%E6%B0%8F%E9%93%BE%E6%80%A7%E8%B4%A8"><span class="toc-text">2.4 马氏链性质</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-1-%E4%B8%8D%E5%8F%AF%E7%BA%A6"><span class="toc-text">2.4.1 不可约</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#2-4-2-%E9%9D%9E%E5%91%A8%E6%9C%9F"><span class="toc-text">2.4.2 非周期</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2-4-3-%E6%AD%A3%E5%B8%B8%E8%BF%94"><span class="toc-text">2.4.3 正常返</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-4-%E9%81%8D%E5%8E%86%E5%AE%9A%E7%90%86"><span class="toc-text">2.4.4 遍历定理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-5-%E5%8F%AF%E9%80%86%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE"><span class="toc-text">2.4.5 可逆马尔可夫链</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%A9%AC%E6%B0%8F%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B"><span class="toc-text">3. 马氏链蒙特卡洛</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E6%80%9D%E6%83%B3"><span class="toc-text">3.1 思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E5%9F%BA%E6%9C%AC%E6%AD%A5%E9%AA%A4"><span class="toc-text">3.2 基本步骤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-MCMC-%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0"><span class="toc-text">3.3 MCMC 与统计学习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-M-H-%E7%AE%97%E6%B3%95"><span class="toc-text">4. M-H 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-text">4.1 基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-1-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE"><span class="toc-text">4.1.1 马尔可夫链</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-2-%E5%BB%BA%E8%AE%AE%E5%88%86%E5%B8%83"><span class="toc-text">4.1.2 建议分布</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-1-3-%E6%BB%A1%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-text">4.1.3 满条件分布</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-Metropolis-Hastings-%E7%AE%97%E6%B3%95"><span class="toc-text">4.2 Metropolis-Hastings 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-%E5%8D%95%E5%88%86%E9%87%8F-Metropolis-Hastings-%E7%AE%97%E6%B3%95"><span class="toc-text">4.3 单分量 Metropolis-Hastings 算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%90%89%E5%B8%83%E6%96%AF%E6%8A%BD%E6%A0%B7"><span class="toc-text">5 吉布斯抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-text">5.1 基本原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-%E5%90%89%E5%B8%83%E6%96%AF%E6%8A%BD%E6%A0%B7%E7%AE%97%E6%B3%95"><span class="toc-text">5.2 吉布斯抽样算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-%E6%8A%BD%E6%A0%B7%E8%AE%A1%E7%AE%97"><span class="toc-text">5.3 抽样计算</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By LiuJT</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>